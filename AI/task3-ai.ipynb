{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":75676,"sourceType":"datasetVersion","datasetId":42780}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\nfrom PIL import Image\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-11-03T13:47:37.055288Z","iopub.execute_input":"2024-11-03T13:47:37.056537Z","iopub.status.idle":"2024-11-03T13:47:37.061811Z","shell.execute_reply.started":"2024-11-03T13:47:37.056487Z","shell.execute_reply":"2024-11-03T13:47:37.060561Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\nprocessor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\ntokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")","metadata":{"execution":{"iopub.status.busy":"2024-11-03T13:47:37.076422Z","iopub.execute_input":"2024-11-03T13:47:37.076867Z","iopub.status.idle":"2024-11-03T13:47:44.262594Z","shell.execute_reply.started":"2024-11-03T13:47:37.076827Z","shell.execute_reply":"2024-11-03T13:47:44.261453Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def generate_caption(image_path):\n    # Load and preprocess the image\n    image = Image.open(image_path).convert(\"RGB\")\n    inputs = processor(images=image, return_tensors=\"pt\").pixel_values\n\n    # Generate the caption\n    output_ids = model.generate(inputs, max_length=16, num_beams=4, early_stopping=True)\n    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    \n    return caption","metadata":{"execution":{"iopub.status.busy":"2024-11-03T13:47:44.265187Z","iopub.execute_input":"2024-11-03T13:47:44.265785Z","iopub.status.idle":"2024-11-03T13:47:44.273611Z","shell.execute_reply.started":"2024-11-03T13:47:44.265726Z","shell.execute_reply":"2024-11-03T13:47:44.272461Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"image_path = \"/kaggle/input/natural-images/natural_images/flower/flower_0002.jpg\"  # Replace with your image file path\ncaption = generate_caption(image_path)\nprint(\"Generated Caption:\", caption)","metadata":{"execution":{"iopub.status.busy":"2024-11-03T13:47:44.275095Z","iopub.execute_input":"2024-11-03T13:47:44.276098Z","iopub.status.idle":"2024-11-03T13:47:48.009232Z","shell.execute_reply.started":"2024-11-03T13:47:44.276040Z","shell.execute_reply":"2024-11-03T13:47:48.008059Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Generated Caption: a row of pink flowers in a flower pot \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}